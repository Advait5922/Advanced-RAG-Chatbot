{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcgA78EfFRYi",
    "outputId": "5c42a672-9a9b-425d-bcb8-812fdc8639b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-parse\n",
      "  Using cached llama_parse-0.4.4-py3-none-any.whl (8.0 kB)\n",
      "Collecting llama-index-embeddings-fastembed\n",
      "  Using cached llama_index_embeddings_fastembed-0.1.4-py3-none-any.whl (2.7 kB)\n",
      "Collecting llama-index\n",
      "  Downloading llama_index-0.10.41-py3-none-any.whl (6.8 kB)\n",
      "Collecting fastembed\n",
      "  Using cached fastembed-0.2.7-py3-none-any.whl (27 kB)\n",
      "Collecting llama-index-vector-stores-qdrant\n",
      "  Using cached llama_index_vector_stores_qdrant-0.2.8-py3-none-any.whl (9.5 kB)\n",
      "Collecting qdrant_client\n",
      "  Using cached qdrant_client-1.9.1-py3-none-any.whl (229 kB)\n",
      "Collecting llama-index-embeddings-ollama\n",
      "  Using cached llama_index_embeddings_ollama-0.1.2-py3-none-any.whl (2.8 kB)\n",
      "Collecting llama_index-llms-ollama\n",
      "  Using cached llama_index_llms_ollama-0.1.5-py3-none-any.whl (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 9)) (1.0.1)\n",
      "Collecting llama-index-llms-groq\n",
      "  Using cached llama_index_llms_groq-0.1.4-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-core>=0.10.29\n",
      "  Downloading llama_index_core-0.10.41-py3-none-any.whl (15.4 MB)\n",
      "     ---------------------------------------- 15.4/15.4 MB 5.8 MB/s eta 0:00:00\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5\n",
      "  Using cached llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3\n",
      "  Using cached llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2\n",
      "  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4\n",
      "  Downloading llama_index_agent_openai-0.2.6-py3-none-any.whl (12 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2\n",
      "  Using cached llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4\n",
      "  Using cached llama_index_readers_file-0.1.23-py3-none-any.whl (36 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13\n",
      "  Using cached llama_index_llms_openai-0.1.21-py3-none-any.whl (11 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48\n",
      "  Using cached llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2\n",
      "  Using cached llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
      "Collecting nest-asyncio<2.0.0,>=1.5.8\n",
      "  Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (3.9.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.3.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (4.66.4)\n",
      "Collecting requests>=2.31.0\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: wrapt in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.14.1)\n",
      "Requirement already satisfied: httpx in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (0.25.2)\n",
      "Requirement already satisfied: dataclasses-json in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (0.6.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (2024.3.1)\n",
      "Collecting SQLAlchemy[asyncio]>=1.4.49\n",
      "  Downloading SQLAlchemy-2.0.30-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (10.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.24.4)\n",
      "Collecting tiktoken>=0.3.3\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-win_amd64.whl (798 kB)\n",
      "     -------------------------------------- 798.9/798.9 kB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.5.3)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.18\n",
      "  Using cached llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (3.8.1)\n",
      "Collecting networkx>=3.0\n",
      "  Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (8.2.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.2.14)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\anaconda\\lib\\site-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (0.9.0)\n",
      "Collecting huggingface-hub<0.21,>=0.20\n",
      "  Using cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Collecting loguru<0.8.0,>=0.7.2\n",
      "  Using cached loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "Collecting tokenizers<0.16,>=0.15\n",
      "  Downloading tokenizers-0.15.2-cp310-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 6.1 MB/s eta 0:00:00\n",
      "Collecting onnx<2.0.0,>=1.15.0\n",
      "  Downloading onnx-1.16.1-cp310-cp310-win_amd64.whl (14.4 MB)\n",
      "     ---------------------------------------- 14.4/14.4 MB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: onnxruntime<2.0.0,>=1.17.0 in d:\\anaconda\\lib\\site-packages (from fastembed->-r requirements.txt (line 4)) (1.18.0)\n",
      "Collecting grpcio<2.0.0,>=1.60.0\n",
      "  Downloading grpcio-1.64.0-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in d:\\anaconda\\lib\\site-packages (from qdrant_client->-r requirements.txt (line 6)) (1.26.14)\n",
      "Collecting portalocker<3.0.0,>=2.7.0\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Collecting grpcio-tools>=1.41.0\n",
      "  Downloading grpcio_tools-1.64.0-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic>=1.10.8 in d:\\anaconda\\lib\\site-packages (from qdrant_client->-r requirements.txt (line 6)) (1.10.14)\n",
      "Collecting llama-index-llms-openai-like<0.2.0,>=0.1.3\n",
      "  Using cached llama_index_llms_openai_like-0.1.3-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant_client->-r requirements.txt (line 6)) (65.6.3)\n",
      "Collecting protobuf<6.0dev,>=5.26.1\n",
      "  Using cached protobuf-5.27.0-cp310-abi3-win_amd64.whl (426 kB)\n",
      "Requirement already satisfied: anyio in d:\\anaconda\\lib\\site-packages (from httpx->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\lib\\site-packages (from httpx->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (2023.11.17)\n",
      "Requirement already satisfied: idna in d:\\anaconda\\lib\\site-packages (from httpx->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda\\lib\\site-packages (from httpx->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.0.2)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda\\lib\\site-packages (from httpx->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.2.0)\n",
      "Collecting h2<5,>=3\n",
      "  Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<0.21,>=0.20->fastembed->-r requirements.txt (line 4)) (23.2)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from huggingface-hub<0.21,>=0.20->fastembed->-r requirements.txt (line 4)) (3.9.0)\n",
      "Collecting openai>=1.1.0\n",
      "  Using cached openai-1.30.5-py3-none-any.whl (320 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in d:\\anaconda\\lib\\site-packages (from llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq->-r requirements.txt (line 10)) (4.40.1)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in d:\\anaconda\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 3)) (4.2.0)\n",
      "Collecting striprtf<0.0.27,>=0.0.26\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: colorama>=0.3.4 in d:\\anaconda\\lib\\site-packages (from loguru<0.8.0,>=0.7.2->fastembed->-r requirements.txt (line 4)) (0.4.6)\n",
      "Collecting win32-setctime>=1.0.0\n",
      "  Using cached win32_setctime-1.1.0-py3-none-any.whl (3.6 kB)\n",
      "Requirement already satisfied: flatbuffers in d:\\anaconda\\lib\\site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4)) (23.5.26)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4)) (1.11.1)\n",
      "Requirement already satisfied: coloredlogs in d:\\anaconda\\lib\\site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4)) (15.0.1)\n",
      "Requirement already satisfied: pywin32>=226 in d:\\anaconda\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant_client->-r requirements.txt (line 6)) (305.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 3)) (2.3.2.post1)\n",
      "Collecting hpack<5,>=4.0\n",
      "  Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Collecting hyperframe<7,>=6.0\n",
      "  Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (2022.7.9)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda\\lib\\site-packages (from openai>=1.1.0->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\anaconda\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq->-r requirements.txt (line 10)) (0.4.3)\n",
      "Collecting transformers<5.0.0,>=4.37.0\n",
      "  Using cached transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "  Using cached transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "  Using cached transformers-4.41.0-py3-none-any.whl (9.1 MB)\n",
      "  Using cached transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "  Using cached transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "  Using cached transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\anaconda\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (0.4.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\anaconda\\lib\\site-packages (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4)) (10.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\anaconda\\lib\\site-packages (from dataclasses-json->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (3.21.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\anaconda\\lib\\site-packages (from pandas->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4)) (1.2.1)\n",
      "Requirement already satisfied: pyreadline3 in d:\\anaconda\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 1)) (1.16.0)\n",
      "Installing collected packages: striprtf, dirtyjson, win32-setctime, SQLAlchemy, requests, protobuf, portalocker, networkx, nest-asyncio, hyperframe, hpack, grpcio, beautifulsoup4, tiktoken, onnx, loguru, huggingface-hub, h2, grpcio-tools, tokenizers, openai, llamaindex-py-client, transformers, qdrant_client, llama-index-legacy, llama-index-core, fastembed, llama-parse, llama-index-vector-stores-qdrant, llama-index-readers-file, llama-index-llms-openai, llama_index-llms-ollama, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-embeddings-ollama, llama-index-embeddings-fastembed, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-llms-openai-like, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-llms-groq, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.39\n",
      "    Uninstalling SQLAlchemy-1.4.39:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.39\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.4\n",
      "    Uninstalling protobuf-4.23.4:\n",
      "      Successfully uninstalled protobuf-4.23.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.8.4\n",
      "    Uninstalling networkx-2.8.4:\n",
      "      Successfully uninstalled networkx-2.8.4\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.6\n",
      "    Uninstalling nest-asyncio-1.5.6:\n",
      "      Successfully uninstalled nest-asyncio-1.5.6\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.59.3\n",
      "    Uninstalling grpcio-1.59.3:\n",
      "      Successfully uninstalled grpcio-1.59.3\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.11.1\n",
      "    Uninstalling beautifulsoup4-4.11.1:\n",
      "      Successfully uninstalled beautifulsoup4-4.11.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.22.2\n",
      "    Uninstalling huggingface-hub-0.22.2:\n",
      "      Successfully uninstalled huggingface-hub-0.22.2\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.3.9\n",
      "    Uninstalling openai-1.3.9:\n",
      "      Successfully uninstalled openai-1.3.9\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.40.1\n",
      "    Uninstalling transformers-4.40.1:\n",
      "      Successfully uninstalled transformers-4.40.1\n",
      "Successfully installed SQLAlchemy-2.0.30 beautifulsoup4-4.12.3 dirtyjson-1.0.8 fastembed-0.2.7 grpcio-1.64.0 grpcio-tools-1.64.0 h2-4.1.0 hpack-4.0.0 huggingface-hub-0.20.3 hyperframe-6.0.1 llama-index-0.10.41 llama-index-agent-openai-0.2.6 llama-index-cli-0.1.12 llama-index-core-0.10.41 llama-index-embeddings-fastembed-0.1.4 llama-index-embeddings-ollama-0.1.2 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-groq-0.1.4 llama-index-llms-openai-0.1.21 llama-index-llms-openai-like-0.1.3 llama-index-multi-modal-llms-openai-0.1.6 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.23 llama-index-readers-llama-parse-0.1.4 llama-index-vector-stores-qdrant-0.2.8 llama-parse-0.4.4 llama_index-llms-ollama-0.1.5 llamaindex-py-client-0.1.19 loguru-0.7.2 nest-asyncio-1.6.0 networkx-3.3 onnx-1.16.1 openai-1.30.5 portalocker-2.8.2 protobuf-5.27.0 qdrant_client-1.9.1 requests-2.32.3 striprtf-0.0.26 tiktoken-0.7.0 tokenizers-0.15.2 transformers-4.39.3 win32-setctime-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "tensorflow-intel 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.0 which is incompatible.\n",
      "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 5.27.0 which is incompatible.\n",
      "sqlmodel 0.0.8 requires SQLAlchemy<=1.4.41,>=1.4.17, but you have sqlalchemy 2.0.30 which is incompatible.\n",
      "opentelemetry-proto 1.24.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.27.0 which is incompatible.\n",
      "googleapis-common-protos 1.63.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "fastapi-utils 0.2.1 requires sqlalchemy<2.0.0,>=1.3.12, but you have sqlalchemy 2.0.30 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.32.3 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_s_zHOWEFgrj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "poiCrUToGquJ",
    "outputId": "ca9a7d28-def9-4a7d-bf75-892141b465df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "LLAMAPARSE_API_KEY = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ygkS1vxJGy91"
   },
   "outputs": [],
   "source": [
    "os.environ['LLAMAPARSE_API_KEY'] = LLAMAPARSE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-xe3eghPHbu7"
   },
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4kdLp5z5Hh3y",
    "outputId": "99070cd3-6b76-4515-90e1-797e7ed37c1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 3bab48f8-b100-4333-bc22-8fbff50d90fd\n",
      "."
     ]
    }
   ],
   "source": [
    "llama_parse_documents = LlamaParse(api_key=LLAMAPARSE_API_KEY, result_type=\"markdown\").load_data(\"Practice of Brahmacharya - Swami Sivananda.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IonUJeg_H4T4",
    "outputId": "6ceae33f-0784-457e-f51e-2e7348f1fcdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llama_parse_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "44_dYczJPY99",
    "outputId": "300e8512-e1f8-4e3b-9a89-c913d73da60b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# PRACTICE OF BRAHMACHARYA\\n\\nBy\\n\\nSRI SWAMI SIVANANDA\\n\\n6(59(\\x0f,/29(\\x0f,*,9(\\x0f\\n\\n385,)<\\x0f,0(',7$7(\\x0f\\n\\n5($/,=(\\n\\nSri Swami Sivananda\\n\\nFounder of\\n\\nThe Divine Life Society\\n\\nA DIVINE LIFE SOCIETY PUBLICATION\\n---\\nFir\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_parse_documents[0].text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdQYwalIPjNS",
    "outputId": "f020d0ec-98d4-49d8-e5bd-f6de004d3237"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(llama_parse_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MbH0E48CP4gO"
   },
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "import qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0twLU_e_QLBi",
    "outputId": "e694e06b-b646-469e-a7b1-9617715bd600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "QDRANT_URL = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Gq9vKwCQQs3d"
   },
   "outputs": [],
   "source": [
    "os.environ['QDRANT_URL'] = QDRANT_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raKtGfQZQzIy",
    "outputId": "e33089cf-9052-48a8-9d67-502f97179653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "QDRANT_API_KEY = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FtS2e0m-REs7"
   },
   "outputs": [],
   "source": [
    "os.environ['QDRANT_API_KEY'] = QDRANT_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "upuSC0iFRKOB"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Defining a function to load parsed data if available, or parse if not\n",
    "def load_or_parse_data():\n",
    "    data_file = \"./data/parsed_data.pkl\"\n",
    "\n",
    "    if os.path.exists(data_file):\n",
    "        # Loading the parsed data from the file\n",
    "        with open(data_file, \"rb\") as f:\n",
    "            parsed_data = pickle.load(f)\n",
    "    else:\n",
    "        # Performing the parsing step and store the result in llama_parse_documents\n",
    "        # llama_parse_documents = LlamaParse(api_key=llamaparse_api_key, result_type=\"markdown\").load_data(\"./data/presentation.pptx\")\n",
    "        llama_parse_documents = LlamaParse(api_key=LLAMAPARSE_API_KEY, result_type=\"markdown\").load_data([\"Practice of Brahmacharya - Swami Sivananda.pdf\"])\n",
    "\n",
    "        # Saving the parsed data to a file\n",
    "        with open(data_file, \"wb\") as f:\n",
    "            pickle.dump(llama_parse_documents, f)\n",
    "\n",
    "        # Setting the parsed data to the variable\n",
    "        parsed_data = llama_parse_documents\n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "ccb5ab59475f47a4ab47c9a954f9448a",
      "13bd8f930a7242ca85e63eb3b92a9466",
      "92b06c55e42445f29a132097fe3d799f",
      "094206c866f6461085c8c02035ebbd00",
      "2dc10adc059a4747995b8df57b1dc896",
      "5b340fdd6e7c4be9a109fd158854167f",
      "9e8398f9b18d402ea6b699f42f5641d4",
      "a0f2d810c3624dd7856d41d04130a048",
      "07c97ef292b0461f8d730ec542df1188",
      "79fd425c2df642e9902c7424e1339f13",
      "d227cf4c5fb04058a26460ebbdadeb47"
     ]
    },
    "id": "d4GUSbKYRnpl",
    "outputId": "dbf5c8d6-e3ee-4172-f9e8-44c018009feb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34843d8f6e244f93b6b1e3dc27a1f1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\AppData\\Local\\Temp\\fastembed_cache\\models--qdrant--bge-base-en-v1.5-onnx-q. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' embed_model = OllamaEmbedding(\\n    model_name=\"nomic-embed-text\",\\n    #model_name=\"llama2\",\\n    base_url=\"http://localhost:11434\",\\n    ollama_additional_kwargs={\"mirostat\": 0},\\n) '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### FastEmbedEmbeddings #############\n",
    "\n",
    "# by default llamaindex uses OpenAI models\n",
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "\"\"\" embed_model = OllamaEmbedding(\n",
    "    model_name=\"nomic-embed-text\",\n",
    "    #model_name=\"llama2\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BKC8WB_tSBJR"
   },
   "outputs": [],
   "source": [
    "#### Setting embed_model other than openAI ( by default used openAI's model)\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ogWy52rcSYia"
   },
   "outputs": [],
   "source": [
    "######### Groq API ###########\n",
    "from llama_index.llms.groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8YwSkOZSo_Y",
    "outputId": "abc84195-d3f9-4963-b411-57927b059cfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "GROQ_API_KEY = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3g-KsfAbSy2z"
   },
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY'] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mKWvvnkoS76X"
   },
   "outputs": [],
   "source": [
    "llm = Groq(model=\"mixtral-8x7b-32768\", api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uU2uHSb2TKa4"
   },
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "\n",
    "client = qdrant_client.QdrantClient(api_key=QDRANT_API_KEY, url=QDRANT_URL,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "24aabb7a806c49ab9ca72c14343eefbf",
      "b1c668d42fc94c3cb72c3f74a81361cf",
      "155c3898f4bf4025ac8717d9358f1af2",
      "a21e027b773343109fc39ecf22fc944c",
      "80e2522f90a747d19ca037c0e1e54354",
      "6ec82c1936094596ad0baff5c09d7c90",
      "bee04812fdbc4b698c318a87e607349d",
      "a30e9f0fd9cb4680a1f7fa8c5a37054d",
      "9a34c04b216940b7a5ae8ae3e6c7d46e",
      "29c9bc8f0195485db9b93ac1cc75286e",
      "4706515611934239a10cb7ac170da1a7",
      "dde0a7f9001747349a46000673dbb15b",
      "6b4a758a3af34808899d1d72f388c44c",
      "e40e8f1a7dbe429d90a3ba1ba6972d57",
      "c47e73f49b6f41f8bf05c7b7d618bc99",
      "44a4e0bf708b4c3db4e05809fbbad041",
      "b0d907d003d8465da0d1ae5cfdc8f490",
      "fc8403e3cddd45459dbccc31d276adb4",
      "bb88e27418434c55b8fdae0379ba9967",
      "01bd063d3ae64c479eacb1dc651050d5",
      "99b91a9d80b449fab475e6f6c2d5ef06",
      "ae58fb1a18b148b2b655d59782206fda"
     ]
    },
    "id": "K8tOelOBTSFh",
    "outputId": "f5fa94cc-9921-4dcf-f4fb-e404c6614e56"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64914d8d2814032bfb61ebad59322b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b75a58bed914b02a4b6039eaeb6cc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector_store = QdrantVectorStore(client=client, collection_name='qdrant_rag')\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(documents=llama_parse_documents, storage_context=storage_context, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7OPqpyKyTwx3"
   },
   "outputs": [],
   "source": [
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9jXLb4mUdQ6",
    "outputId": "066e669f-bb3a-4106-a703-fd510130bc6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swami Sivananda emphasizes the importance of brahmacharya, which is often translated as celibacy or sexual continence, as a fundamental principle for self-realization and divine perfection. He teaches that brahmacharya is the basis of a radiant and enthusiastic divine life, and it is an essential aspect of the gospel of Gurudev's teachings for mankind.\n",
      "\n",
      "Swami Sivananda explains that the aspiration for self-realization and atma jnana (self-knowledge) leads to a principled life, which in turn fosters self-control, self-mastery, and character. This character forms the foundation for brahmacharya, which is the basis for immortality, divine perfection, liberation, and a fulfilling life.\n",
      "\n",
      "He highlights the significance of brahmacharya by pointing out that the present-day degradation and moral decline can be attributed to the flouting of scriptural norms and the lack of understanding of the ancient wisdom regarding sex and its regulation. Swami Sivananda aims to fill this lacuna by offering guidance to modern youth through his books and teachings.\n",
      "\n",
      "Swami Sivananda has written extensively on brahmacharya, including a whole book on the subject, titled \"Practice of Brahmacharya.\" Other spiritual teachers, such as Swami Jagadishananda and Sri Swami Narayanananda Saraswati, have also contributed to the understanding of brahmacharya through their writings.\n",
      "\n",
      "In summary, Swami Sivananda views brahmacharya as a crucial aspect of self-realization, divine perfection, and a fulfilling life. He encourages a principled life based on ethics, morality, self-control, and self-mastery, which ultimately leads to the development of character and brahmacharya. Swami Sivananda's teachings aim to provide guidance and fill the void left by modern society's lack of understanding of ancient wisdom regarding sex and its regulation.\n"
     ]
    }
   ],
   "source": [
    "# creating a query engine for the index\n",
    "query_engine = index.as_query_engine()\n",
    "query = \"What are the ideologies of Swami Sivananda about Brahmacharya? Answer in detail make it simple to read\"\n",
    "\n",
    "# querying the query engine\n",
    "response = query_engine.query(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01bd063d3ae64c479eacb1dc651050d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "07c97ef292b0461f8d730ec542df1188": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "094206c866f6461085c8c02035ebbd00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79fd425c2df642e9902c7424e1339f13",
      "placeholder": "​",
      "style": "IPY_MODEL_d227cf4c5fb04058a26460ebbdadeb47",
      "value": " 5/5 [00:00&lt;00:00, 153.90it/s]"
     }
    },
    "13bd8f930a7242ca85e63eb3b92a9466": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b340fdd6e7c4be9a109fd158854167f",
      "placeholder": "​",
      "style": "IPY_MODEL_9e8398f9b18d402ea6b699f42f5641d4",
      "value": "Fetching 5 files: 100%"
     }
    },
    "155c3898f4bf4025ac8717d9358f1af2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a30e9f0fd9cb4680a1f7fa8c5a37054d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a34c04b216940b7a5ae8ae3e6c7d46e",
      "value": 1
     }
    },
    "24aabb7a806c49ab9ca72c14343eefbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b1c668d42fc94c3cb72c3f74a81361cf",
       "IPY_MODEL_155c3898f4bf4025ac8717d9358f1af2",
       "IPY_MODEL_a21e027b773343109fc39ecf22fc944c"
      ],
      "layout": "IPY_MODEL_80e2522f90a747d19ca037c0e1e54354"
     }
    },
    "29c9bc8f0195485db9b93ac1cc75286e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dc10adc059a4747995b8df57b1dc896": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44a4e0bf708b4c3db4e05809fbbad041": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4706515611934239a10cb7ac170da1a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b340fdd6e7c4be9a109fd158854167f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b4a758a3af34808899d1d72f388c44c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0d907d003d8465da0d1ae5cfdc8f490",
      "placeholder": "​",
      "style": "IPY_MODEL_fc8403e3cddd45459dbccc31d276adb4",
      "value": "Generating embeddings: 100%"
     }
    },
    "6ec82c1936094596ad0baff5c09d7c90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79fd425c2df642e9902c7424e1339f13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80e2522f90a747d19ca037c0e1e54354": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92b06c55e42445f29a132097fe3d799f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0f2d810c3624dd7856d41d04130a048",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07c97ef292b0461f8d730ec542df1188",
      "value": 5
     }
    },
    "99b91a9d80b449fab475e6f6c2d5ef06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a34c04b216940b7a5ae8ae3e6c7d46e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9e8398f9b18d402ea6b699f42f5641d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0f2d810c3624dd7856d41d04130a048": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a21e027b773343109fc39ecf22fc944c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29c9bc8f0195485db9b93ac1cc75286e",
      "placeholder": "​",
      "style": "IPY_MODEL_4706515611934239a10cb7ac170da1a7",
      "value": " 1/1 [00:00&lt;00:00, 20.17it/s]"
     }
    },
    "a30e9f0fd9cb4680a1f7fa8c5a37054d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae58fb1a18b148b2b655d59782206fda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0d907d003d8465da0d1ae5cfdc8f490": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1c668d42fc94c3cb72c3f74a81361cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ec82c1936094596ad0baff5c09d7c90",
      "placeholder": "​",
      "style": "IPY_MODEL_bee04812fdbc4b698c318a87e607349d",
      "value": "Parsing nodes: 100%"
     }
    },
    "bb88e27418434c55b8fdae0379ba9967": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bee04812fdbc4b698c318a87e607349d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c47e73f49b6f41f8bf05c7b7d618bc99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99b91a9d80b449fab475e6f6c2d5ef06",
      "placeholder": "​",
      "style": "IPY_MODEL_ae58fb1a18b148b2b655d59782206fda",
      "value": " 5/5 [00:11&lt;00:00,  2.32s/it]"
     }
    },
    "ccb5ab59475f47a4ab47c9a954f9448a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_13bd8f930a7242ca85e63eb3b92a9466",
       "IPY_MODEL_92b06c55e42445f29a132097fe3d799f",
       "IPY_MODEL_094206c866f6461085c8c02035ebbd00"
      ],
      "layout": "IPY_MODEL_2dc10adc059a4747995b8df57b1dc896"
     }
    },
    "d227cf4c5fb04058a26460ebbdadeb47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dde0a7f9001747349a46000673dbb15b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b4a758a3af34808899d1d72f388c44c",
       "IPY_MODEL_e40e8f1a7dbe429d90a3ba1ba6972d57",
       "IPY_MODEL_c47e73f49b6f41f8bf05c7b7d618bc99"
      ],
      "layout": "IPY_MODEL_44a4e0bf708b4c3db4e05809fbbad041"
     }
    },
    "e40e8f1a7dbe429d90a3ba1ba6972d57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb88e27418434c55b8fdae0379ba9967",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_01bd063d3ae64c479eacb1dc651050d5",
      "value": 5
     }
    },
    "fc8403e3cddd45459dbccc31d276adb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
